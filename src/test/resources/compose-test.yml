version: "3.7"
services:
  zookeeper:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    hostname: zookeeper
    command: zookeeper-server-start
    networks:
      - confluent
    environment:
      - KAFKA_SERVER_ID=1
      - KAFKA_clientPort=2181
      - KAFKA_dataDir=/tmp/zookeeper
      - KAFKA_tickTime=2000
      - KAFKA_4lw_commands_whitelist=stat, ruok, conf, isro
      - KAFKA_OPTS=-Xms128m -Xmx128m
    healthcheck:
      test: test `echo "ruok" | nc localhost 2181 | grep "imok"`
      interval: 2s
      timeout: 2s
      retries: 3
      start_period: 2s

  kafka:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    hostname: kafka
    command: kafka-server-start
    ports:
      - 9092:9092
    networks:
      - confluent
    depends_on:
      - zookeeper
    environment:
      - KAFKA_broker_id=101
      - KAFKA_zookeeper_connect=zookeeper:2181
      - KAFKA_listener_security_protocol_map=PLAINTEXT:PLAINTEXT
      - KAFKA_advertised_listeners=PLAINTEXT://kafka:9092
      - KAFKA_listeners=PLAINTEXT://:9092
      - KAFKA_inter_broker_listener_name=PLAINTEXT
      - KAFKA_auto_create_topics_enable=true
      - KAFKA_delete_topic_enable=true
      - KAFKA_offsets_topic_replication_factor=1
      - KAFKA_OPTS=-Xms256m -Xmx256m
    restart: on-failure
    healthcheck:
      test: nc -z localhost 9092
      interval: 2s
      timeout: 2s
      retries: 3
      start_period: 2s

  kafka-connect:
    image: "ianitrix/kafka:${CONFLUENT_VERSION}"
    command: connect-distributed
    hostname: kafka-connect
    ports:
      - 8083:8083
    networks:
      - confluent
    depends_on:
      - kafka
    healthcheck:
      test: test `curl -s -o /dev/null -w "%{http_code}" http://localhost:8083/connectors` = 200
      interval: 2s
      timeout: 2s
      retries: 10
      start_period: 2s
    environment:
      - KAFKA_OPTS=-Xms512m -Xmx512m
      - KAFKA_bootstrap_servers=kafka:9092
      - KAFKA_rest_port=8083
      - KAFKA_group_id=connect
      - KAFKA_config_storage_topic=_connect-config
      - KAFKA_offset_storage_topic=_connect-offsets
      - KAFKA_status_storage_topic=_connect-status
      - KAFKA_replication_factor=1
      - KAFKA_config_storage_replication_factor=1
      - KAFKA_offset_storage_replication_factor=1
      - KAFKA_status_storage_replication_factor=1
      - KAFKA_key_converter=org.apache.kafka.connect.json.JsonConverter
      - KAFKA_value_converter=org.apache.kafka.connect.json.JsonConverter
      - KAFKA_key_converter_schemas_enable=false
      - KAFKA_value_converter_schemas_enable=false
      - KAFKA_internal_key_converter=org.apache.kafka.connect.json.JsonConverter
      - KAFKA_internal_value_converter=org.apache.kafka.connect.json.JsonConverter
      - KAFKA_rest_advertised_host_name=kafka-connect
      - KAFKA_plugin_path=/confluent-${CONFLUENT_VERSION}/share/java
      - KAFKA_log4j_root_loglevel=INFO
      - KAFKA_log4j_loggers=org.reflections=ERROR
    restart: on-failure

  elasticsearch:
    image: "elasticsearch:${ELASTIC_VERSION}"
    hostname: elasticsearch
    ports:
      - 9200:9200
    healthcheck:
      test: test `curl -s -o /dev/null -w "%{http_code}" http://localhost:9200/_cluster/health` = 200
      interval: 2s
      timeout: 2s
      retries: 10
      start_period: 2s
    environment:
      - node.name=elasticsearch
      - cluster.name=es-docker-cluster
      - discovery.seed_hosts=elasticsearch
      - cluster.initial_master_nodes=elasticsearch
      - bootstrap.memory_lock=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    networks:
      - confluent

  load-es-connector-trace:
    image: "curlimages/curl:7.69.0"
    hostname: curl
    entrypoint:
      - "/deployConnector.sh"
      - "http://kafka-connect:8083"
      - ""
      - "body.json"
    depends_on:
      - kafka-connect
      - elasticsearch
    networks:
      - confluent
    restart: on-failure
    volumes:
      - ./dataTest/deployConnector.sh:/deployConnector.sh:ro
      - ./dataTest/connectorTrace.json:/body.json:ro

  kafkahq:
    image: tchiotludo/kafkahq:0.12.0
    container_name: kafkahq
    networks:
      - confluent
    ports:
      - "8080:8080"
    environment:
      KAFKAHQ_CONFIGURATION: |
        kafkahq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka:9092"
              schema-registry:
                url: "http://schema-registry:8081"
              connect:
                - name: default
                  url: "http://kafka-connect:8083"


networks:
  confluent:
    name: confluent

